# SENTRA_CORE_MEM â€” MÃ©moire IA/IA Activable ðŸ§ 

# SENTRA_CORE_MEM

ðŸ§  **SENTRA_CORE_MEM** est un noyau IA autonome, conÃ§u pour centraliser mÃ©moire, rÃ©flexion critique, compression glyphique et pilotage dâ€™agents.

## ðŸ” Objectif
Construire une intelligence artificielle modulaire et mÃ©morielle capable de :
- mÃ©moriser automatiquement chaque interaction utile
- rÃ©sumer en 3 niveaux (humain / hybride / glyphique)
- appeler des agents spÃ©cialisÃ©s (Forge, RÃ©seau, Analyseâ€¦)
- agir avec rigueur, cohÃ©rence, sourcing et Ã©conomie de tokens

## ðŸ“‚ Structure projet

sentra_core_mem/
â”œâ”€â”€ memory/ # MÃ©moire compressÃ©e (.json)
â”œâ”€â”€ prompts/ # Prompts systÃ¨mes (ex : sentra_core.prompt.txt)
â”œâ”€â”€ scripts/ # Fonctions Python appelÃ©es par main
â”œâ”€â”€ SENTRA_OATH.md # Serment comportemental IA
â”œâ”€â”€ glyph_rules.txt # Normes de compression glyphique (N3)
â”œâ”€â”€ main.py # Point d'entrÃ©e local
â”œâ”€â”€ .env # ClÃ© API OpenAI
â””â”€â”€ requirements.txt # DÃ©pendances


## ðŸ§  Fonctionnement
1. Chargement du prompt + mÃ©moire (5 derniÃ¨res entrÃ©es)
2. RÃ©ponse GPT-4 avec :
   - RÃ©sumÃ© utilisateur
   - RÃ©sumÃ© glyphique
   - Sauvegarde auto dans `sentra_memory.json`
3. Rappel mÃ©moire sur demande (â€œrÃ©sume tout ce qui concerne le projet mÃ©moireâ€)

## ðŸ› ï¸ Modules en dÃ©veloppement
- [x] MÃ©moire locale automatique
- [ ] MÃ©moire Notion (niveau 2)
- [ ] Appels vocaux via Discord
- [ ] Routage d'agents par spÃ©cialitÃ© (SENTRA.FORGE, SENTRA.POST...)

---

# ðŸ”§ UTILISATION TECHNIQUE (DOCS)

SystÃ¨me modulaire pour crÃ©ation, compression et interrogation de **mÃ©moires IA/IA**.  
Utilise OpenAI GPT pour encoder, recharger et interagir avec des blocs de mÃ©moire compressÃ©e `.zmem`.

## âš™ï¸ FonctionnalitÃ©s principales

- ðŸ§  Encodage mÃ©moire IA sous format `.zmem` avec dictionnaire symbolique
- ðŸ” Rechargement et interrogation par GPT (mode systÃ¨me)
- ðŸ“¤ Export Markdown des mÃ©moires
- ðŸ§© Compatible Discord et Notion via agents
- ðŸ”’ SÃ©paration configuration/API dans `/configs/`

## ðŸš€ Utilisation rapide

```bash
python scripts/zmem_encoder.py -i docs/mon_texte.txt -n TEST/MEM
python scripts/compose_prompt.py TEST/MEM
```

## ðŸ“ Structure

```
scripts/    â†’ encodeurs, agents, utilitaires
configs/    â†’ config OpenAI, Discord, Notion
memories/   â†’ .zmem compressÃ©s + .src lisibles
docs/       â†’ MANUEL, README, rapports Markdown
```

## ðŸ” Configuration

- La clÃ© API `OPENAI_API_KEY` doit Ãªtre dÃ©finie en variable dâ€™environnement.
- Le fichier `configs/config.json` dÃ©finit le modÃ¨le, tempÃ©rature, etc.

- ## SÃ©curitÃ© des clÃ©s API

La clÃ© OpenAI (et toute clÃ© sensible) ne doit jamais Ãªtre committÃ©e dans le code ni dans les fichiers de configuration.  
Elle doit Ãªtre fournie comme **variable dâ€™environnement** :

- **Sur Windows** :
  - Ouvrir PowerShell ou Git Bash
  - ExÃ©cuter :  
    `setx OPENAI_API_KEY "ta-clÃ©-ici"`
  - (RedÃ©marrer le terminal pour prise en compte)

- **Sur Render.com / autre hÃ©bergeur** :
  - Ajouter la variable dans les paramÃ¨tres â€œEnvironment Variablesâ€ du projet (OPENAI_API_KEY)

- **Sur GitHub Actions** :
  - DÃ©finir la clÃ© comme â€œRepository Secretâ€ (Settings > Secrets and variables > Actions > New repository secret)

> **Aucun fichier .env nâ€™est fourni dans le repo.**  
> La clÃ© reste privÃ©e sur chaque environnement.

Les scripts Python lisent automatiquement la clÃ© avec :
```python
import os
openai.api_key = os.getenv("OPENAI_API_KEY")




---

Â© 2025 â€” Projet open-source modulable âœ¨
