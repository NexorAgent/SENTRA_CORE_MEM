# SENTRA_CORE_MEM â€” MÃ©moire IA autonome ğŸ§ 

**SENTRA_CORE_MEM** est un noyau IA capable de compresser ses souvenirs, d'orchestrer plusieurs agents, de fonctionner hors SaaS et maintenant d'exploiter un cortex IA local (DeepSeek R1) connectÃ© en API. Le projet reste entiÃ¨rement open source et modulable.

---

## Objectif
- MÃ©moriser chaque interaction utile
- RÃ©sumer Ã  trois niveaux (humain, hybride, glyphique)
- Mobiliser des agents dÃ©diÃ©s (Markdown, Notion, Discordâ€¦)
- Optimiser l'usage des tokens et la mÃ©moire centrale (vectorielle)
- BÃ©nÃ©ficier dâ€™une IA reasoning en local (DeepSeek R1/7B via Ollama)
- Orchestrer lâ€™automatisation via n8n, fallback cloud/local

---

## Architecture actuelle (MAJ 2025-07-15)

- **VPS OVH** : orchestration, mÃ©moire centrale (ChromaDB), API REST (FastAPI), agents et automatisations (n8n), backups, logs, traÃ§abilitÃ©
- **PC local (DeepSeek R1/7B quantisÃ©)** : reasoning, rÃ©sumÃ©, brainstorming, agents spÃ©cialisÃ©s (via Ollama/llama.cpp, API REST locale ou tunnel sÃ©curisÃ©)
- **InteropÃ©rabilitÃ©** : tunnel Cloudflare sÃ©curisÃ© et reverse proxy HTTPS
- **Docker Compose** : orchestration des services API, Discord, n8n et volumes
- **Fallback IA** : bascule automatique OpenAI â†’ DeepSeek local pour le reasoning

---

## Structure du projet
```text
sentra_core_mem/
â”œâ”€â”€ memory/            # MÃ©moire compressÃ©e (.json)
â”œâ”€â”€ scripts/           # Encodeurs, agents, automatisations
â”œâ”€â”€ sentra/            # Noyau, orchestrateur, vector search
â”œâ”€â”€ reports/           # Rapports gÃ©nÃ©rÃ©s
â”œâ”€â”€ logs/              # Journaux d'exÃ©cution
â”œâ”€â”€ docs/              # Documentation, changelog, plannings
â”œâ”€â”€ docker-compose.yml # Orchestration API, n8n, Discord, etc.
â””â”€â”€ projects/          # MultimÃ©moire, journal, sandbox/prod
```

## Installation et configuration
Cloner le dÃ©pÃ´tÂ :

bash
Copier
Modifier
git clone https://github.com/sentra-core/sentra_core_mem.git
cd sentra_core_mem
CrÃ©er un environnement virtuel puis installer les dÃ©pendancesÂ :

bash
Copier
Modifier
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
Copier .env.example en .env et renseigner les clÃ©sÂ :

ini
Copier
Modifier
OPENAI_API_KEY=sk-...
NOTION_TOKEN=secret_...
NOTION_DB_ID=abcd1234...
DISCORD_BOT_TOKEN=MTA...
VÃ©rifier configs/config.json puis lancer le test rapideÂ :

bash
Copier
Modifier
python scripts/sentra_check.py
Aucun fichier .env n'est fourni dans le dÃ©pÃ´tÂ ; chaque environnement garde ses clÃ©s privÃ©es.

Utilisation de l'API
DÃ©marrer l'API FastAPI
Pour tester localement l'API (plugin ChatGPT), lancezÂ :

bash
Copier
Modifier
uvicorn scripts.api_sentra:app --reload --port 5000

### Outils MCP disponibles

L'API FastAPI expose dÃ©sormais ses capacitÃ©s sous forme d'outils MCP. Chaque requÃªte transporte au minimum le champ `user` pour l'audit et, lorsqu'une Ã©criture est rÃ©alisÃ©e, un `agent` permettant d'attribuer l'action.

- **`files.read`** (`POST /files/read`) â€“ lit un fichier dans `/projects`, `/reports` ou `/students`.
  ```json
  {
    "user": "ops",
    "path": "/projects/demo/fichiers/todo.md"
  }
  ```
- **`files.write`** (`POST /files/write`) â€“ crÃ©e ou met Ã  jour un fichier et pousse l'artefact dans Git.
  ```json
  {
    "user": "ops",
    "agent": "scribe",
    "path": "/projects/demo/fichiers/todo.md",
    "content": "- [ ] PrÃ©parer la dÃ©mo",
    "idempotency_key": "todo-v1"
  }
  ```
- **`memory.note.add`** (`POST /memory/note/add`) â€“ ajoute une note horodatÃ©e Ã  la mÃ©moire centrale.
  ```json
  {
    "user": "ops",
    "agent": "scribe",
    "note": {
      "text": "Organiser la rÃ©union de planification",
      "tags": ["planning", "demo"],
      "metadata": {"source": "discord"},
      "note_id": "planning-001"
    }
  }
  ```
- **`memory.note.find`** (`POST /memory/note/find`) â€“ effectue une recherche full-text ou par tags.
  ```json
  {
    "user": "ops",
    "query": "rÃ©union demo",
    "tags": ["planning"],
    "limit": 5
  }
  ```
- **`bus.send`** (`POST /bus/send`) â€“ publie un message structurÃ© dans la feuille Google "bus".
  ```json
  {
    "user": "ops",
    "agent": "dispatcher",
    "spreadsheet_id": "1Abc...",
    "worksheet": "bus",
    "payload": {
      "from": "sentra",
      "to": "codex",
      "topic": "draft",
      "goal": "Ship v2 spec"
    },
    "idempotency_key": "draft-2025-01-20"
  }
  ```
- **`bus.poll`** (`POST /bus/poll`) â€“ rÃ©cupÃ¨re les messages suivant un statut donnÃ©.
  ```json
  {
    "user": "ops",
    "spreadsheet_id": "1Abc...",
    "worksheet": "bus",
    "status": "pending",
    "limit": 10
  }
  ```
- **`bus.updateStatus`** (`POST /bus/updateStatus`) â€“ clÃ´ture ou relance un message du bus.
  ```json
  {
    "user": "ops",
    "agent": "dispatcher",
    "spreadsheet_id": "1Abc...",
    "worksheet": "bus",
    "message_id": "bus-2025-0001",
    "status": "done"
  }
  ```
- **`gcal.create_event`** (`POST /google/gcal/create_event`) â€“ planifie un Ã©vÃ©nement dans Google Agenda.
  ```json
  {
    "user": "ops",
    "agent": "calendar",
    "calendar_id": "primary",
    "summary": "Demo SENTRA",
    "description": "Synchro produit",
    "location": "Visio",
    "start": "2025-01-20T09:00:00Z",
    "end": "2025-01-20T10:00:00Z",
    "timezone": "Europe/Paris",
    "attendees": ["lead@example.com"],
    "idempotency_key": "demo-2025-01-20"
  }
  ```
- **`gdrive.upload`** (`POST /google/gdrive/upload`) â€“ envoie un fichier (base64) vers Google Drive.
  ```json
  {
    "user": "ops",
    "agent": "uploader",
    "name": "rapport.pdf",
    "mime_type": "application/pdf",
    "content_base64": "JVBERi0xLjQKJ...",
    "folder_id": "abc123"
  }
  ```
- **`rag.index`** (`POST /rag/index`) â€“ indexe un lot de documents dans la collection ChromaDB.
  ```json
  {
    "user": "ops",
    "agent": "rag-writer",
    "collection": "prod-notes",
    "documents": [
      {
        "text": "Spec SENTRA v2",
        "metadata": {"source": "wiki"},
        "id": "spec-v2"
      }
    ]
  }
  ```
- **`rag.query`** (`POST /rag/query`) â€“ interroge la collection vectorielle et renvoie les passages les plus proches.
  ```json
  {
    "user": "ops",
    "collection": "prod-notes",
    "query": "rÃ©sumÃ© architecture",
    "n_results": 3
  }
  ```

Chaque `files.write` dÃ©clenche automatiquement un `git commit` suivi d'un `git push`. Les notes restent sauvegardÃ©es dans `memory/sentra_memory.json` ainsi que dans `projects/<nom>/fichiers/Z_MEMORIAL.md`. Lorsquâ€™un champ `project` est fourni, elles sont aussi ajoutÃ©es dans `projects/<slug>/fichiers/memoire_<slug>.md`.

#### Bus Google Sheet & workflow `bus-dispatch`

Le bus d'orchestration repose sur une feuille Google Sheet structurÃ©e avec les colonnes `id | ts | from | to | topic | goal | context_json | status | error | last_update`Â :

- `id` â€“ identifiant unique gÃ©nÃ©rÃ© par `bus.send` (utilisÃ© pour les mises Ã  jour).
- `ts` â€“ horodatage d'insertion.
- `from` / `to` â€“ agent source et cible.
- `topic` â€“ sujet court lisible.
- `goal` â€“ objectif dÃ©taillÃ© transmis aux agents.
- `context_json` â€“ charge utile complÃ¨te sÃ©rialisÃ©e (JSON).
- `status` â€“ Ã©tat du message (`pending`, `queued`, `running`, `done`, `error`).
- `error` â€“ dernier message d'erreur remontÃ© par un agent.
- `last_update` â€“ date de la derniÃ¨re modification par un outil ou un opÃ©rateur.

Le workflow n8n `bus-dispatch` se dÃ©ploie en trois Ã©tapesÂ : (1) un nÅ“ud *Google Sheets Watch* Ã©coute les lignes dont le `status` est `pending`; (2) un nÅ“ud *Discord* publie la mission sur le canal opÃ©rateurs avec un lien vers la ligne ; (3) un nÅ“ud *Google Sheets Update* applique la rÃ©ponse (nouveau `status`, horodatage `last_update`, Ã©ventuel `error`). Ainsi, toute boucle `bus.send â†’ bus.poll â†’ bus.updateStatus` reste synchronisÃ©e entre la feuille, Discord et les agents SENTRA.

## ğŸ”’ Obfuscation glyphique
L'option `--obfuscate` du script `run_auto_translator.py` attribue des glyphes alÃ©atoires Ã  chaque balise. Le mapping gÃ©nÃ©rÃ© est Ã©crit dans un fichier `<nom>_mapping.json` (ou chemin dÃ©fini par `--map-out`). **AttentionÂ :** perdre ce fichier rend la dÃ©compression impossible. Conservez-le prÃ©cieusement ou lancez le script sans obfuscation si la rÃ©cupÃ©ration prÃ©vaut.

Pour restaurer un texteÂ :
```python
from scripts.glyph.glyph_generator import decompress_with_dict
import json
mapping = json.load(open("FICHIER_mapping.json", "r", encoding="utf-8"))
plain = decompress_with_dict(glyph_text, mapping)
```

## ğŸ”„ Vue d'ensemble du workflow
Un cycle complet peut Ãªtre exÃ©cutÃ© manuellement ou via schedulerÂ :
```
encode â†’ load â†’ sync â†’ report
```
Le script `sentra/orchestrator.py` centralise ces Ã©tapes et gÃ¨re la distribution vers les agents.

## ğŸ“– Exemples d'utilisation
### CrÃ©er et interroger une mÃ©moire
```bash
python scripts/zmem_encoder.py -i docs/mon_texte.txt -n DEMO/MEM
python scripts/compose_prompt.py DEMO/MEM
```
ğŸ“– Exemples d'utilisation avancÃ©e
Orchestration mÃ©moire : vector search (ChromaDB), rÃ©sumÃ© markdown, fusion intelligente de notes

Brainstorming/code/veille par DeepSeek R1 via API Ollama (voir planning)

Automatisation n8nÂ : backup, synchronisation, extraction, dashboard, surveillance
### Exemple n8n
1. **HTTP Request** â†’ `POST /memory/note/add` avec un contenu gÃ©nÃ©rÃ©
2. **GitHub** â†’ `pull` puis `push` automatique
3. **Discord** â†’ alerte en cas dâ€™Ã©chec
Le tout exposÃ© derriÃ¨re Cloudflare pour sÃ©curiser l'accÃ¨s.
```

### Orchestrateur & agents
```bash
# Encodage via l'orchestrateur
python sentra/orchestrator.py encode --input docs/mon_texte.txt --name DEMO/MEM

# Synchronisation Notion + Discord
python sentra/orchestrator.py sync --target all

# GÃ©nÃ©ration de rapport pour une date
python sentra/orchestrator.py report --date 2025-06-01
```
Les agents peuvent aussi Ãªtre appelÃ©s directementÂ :
```bash
python scripts/agent_markdown.py           # Rapport Markdown
python scripts/agent_notion.py             # Synchronisation Notion
python sentra/zarch.py --query "Alpha"     # Recherche dans la mÃ©moire
```

### Autres scripts utiles
```bash
python scripts/archive.py       # Archiver le projet
python scripts/main.py          # Test global de l'installation
```
> **Aucun fichier .env nâ€™est fourni dans le repo.**
> La clÃ© reste privÃ©e sur chaque environnement.

Les scripts Python lisent automatiquement la clÃ© avecÂ :
```python
import os
openai.api_key = os.getenv("OPENAI_API_KEY")
```

## Documentation complÃ©mentaire
- [CHANGELOG](docs/CHANGELOG.md)
- [PLANNING](docs/PLANNING_SENTRA_CORE_MEM.md)

En mode Render/cloud, le push git effectif nÃ©cessite un token/clÃ© SSH configurÃ©. Les endpoints sont sÃ©curisÃ©s par obscuritÃ© (non publics) mais peuvent Ãªtre protÃ©gÃ©s (bearer token, etc.).

### Docker Compose
Un fichier `docker-compose.yml` permet de lancer l'API FastAPI, le bot Discord, n8n et l'orchestrateurÂ :
```bash
docker compose up -d
```

ğŸ§­ PHASE 0 â€“ Audit & PrÃ©paration (Semaine 0)
ğŸ¯ Objectif :
PrÃ©parer le terrain cÃ´tÃ© VPS pour accueillir toute lâ€™architecture SENTRA_CORE_MEM (API, Orchestrateur, n8n, etc.) de faÃ§on sÃ©curisÃ©e, stable et documentÃ©e.

âœ… 0.1 â€” Audit du VPS
ğŸ” VÃ©rifier les ressources disponibles
Connecte-toi en SSH :

bash
Copier
Modifier
ssh debian@<IP_DU_VPS>
Et lance les commandes suivantes :

bash
Copier
Modifier
# CPU
lscpu

# RAM
free -h

# Stockage
df -h

# RÃ©seau + nom machine
hostnamectl && ip a
ğŸ“Œ Objectif : confirmer que ton VPS a au moins 2 vCPU, 4 Go RAM et 20 Go de libre pour les besoins de base.

ğŸ” VÃ©rification sÃ©curitÃ© SSH
bash
Copier
Modifier
# VÃ©rifie si fail2ban est installÃ©
sudo systemctl status fail2ban

# VÃ©rifie si UFW est actif
sudo ufw status verbose
ğŸ”§ Si nÃ©cessaire :

bash
Copier
Modifier
# Installer fail2ban
sudo apt install fail2ban -y

# Installer et activer UFW
sudo apt install ufw -y
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow ssh
sudo ufw enable
ğŸ³ 0.2 â€” Installation Docker / Docker Compose / Git
bash
Copier
Modifier
# Mise Ã  jour
sudo apt update && sudo apt upgrade -y

# Installation Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Ajout de lâ€™utilisateur au groupe Docker
sudo usermod -aG docker $USER
newgrp docker

# VÃ©rification Docker
docker --version

# Docker Compose plugin (Debian >= 11)
sudo apt install docker-compose-plugin -y
docker compose version

# Installation Git
sudo apt install git -y
git --version
ğŸ“ 0.3 â€” CrÃ©ation du dossier projet "propre"
bash
Copier
Modifier
# Clonage du projet
git clone https://github.com/NexorAgent/SENTRA_CORE_MEM.git
cd SENTRA_CORE_MEM

# CrÃ©ation du .env
cp .env.example .env
nano .env  # (adapter les clÃ©s API, ports, etc.)
ğŸ“„ 0.4 â€” RÃ©daction documentation initiale
CrÃ©e un fichier README_PHASE0.md avec :

markdown
Copier
Modifier
# ğŸ“„ SENTRA_CORE_MEM â€” Phase 0 : Audit & PrÃ©paration

## ğŸ” VPS
- CPU : 2vCPU
- RAM : 4 Go
- Disque libre : 25 Go
- Nom de machine : sentra-core
- OS : Debian 11

## ğŸ” SÃ©curitÃ©
- SSH activÃ©, port : 22
- Fail2ban actif
- UFW actif, rÃ¨gles :
  - allow ssh
  - allow 80, 443 (pour Nginx / tunnel)
- OVH Firewall externe : dÃ©sactivÃ© (si cloudflared)

## ğŸ³ Docker & Git
- Docker : âœ… installÃ©
- Docker Compose : âœ… OK (v2)
- Git : âœ… installÃ©

## ğŸ“ Dossier projet
- Structure clonÃ©e depuis GitHub
- .env gÃ©nÃ©rÃ© avec clÃ©s API

## âœ… VÃ©rifications OK
- SSH : âœ…
- Git : âœ…
- Docker : âœ…
- Ports API & n8n ouverts : âœ…
âœ… 0.5 â€” VÃ©rification finale
bash
Copier
Modifier
# Tester que tout fonctionne
docker --version
docker compose version
git status
ğŸ“¦ Fichiers Ã  ajouter au Git (si projet privÃ©)
plaintext
Copier
Modifier
ğŸ“ SENTRA_CORE_MEM/
â”œâ”€â”€ README_PHASE0.md
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
Tu peux aussi pousser les premiÃ¨res infos dâ€™audit dans ton repo Git :

bash
Copier
Modifier
git add README_PHASE0.md
git commit -m "Ajout audit phase 0"
git push origin main
â±ï¸ DurÃ©e estimÃ©e
Ã‰tape	DurÃ©e max
Audit SSH + CPU/RAM	10 min
Installation Docker/Git	20 min
Configuration UFW	10 min
Clonage + .env	10 min
RÃ©daction README audit	15 min

â³ Total : 1h max si tout est prÃªt.

Â© 2025 â€” Projet openâ€‘source modulable âœ¨

## âœ… Tests automatisÃ©s

Le paquet `tests/` contient une suite Pytest rafraÃ®chie couvrant chaque outil MCP (`files`, `memory`, `bus`, `google`, `rag`) en plus du scÃ©nario E2E (marquÃ© `slow`). Les fixtures isolent les dÃ©pendances externes (Git, Google Sheet, n8n, Discord) en les simulant.

```bash
pytest -k "files"
pytest -k "memory"
pytest -k "bus"
pytest -k "google"
pytest -k "rag"
```

Lancer `pytest` sans filtre exÃ©cute l'ensemble de la suite, et `pytest -m "not slow"` permet d'exclure le test de bout en bout si besoin.

## Licence
Ce projet est distribuÃ© sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus d'informations.
