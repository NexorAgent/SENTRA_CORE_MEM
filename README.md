# SENTRA_CORE_MEM ‚Äî M√©moire IA/IA Activable üß†ü¶ã

# SENTRA_CORE_MEM

üß† **SENTRA_CORE_MEM** est un noyau IA autonome, con√ßu pour centraliser m√©moire, r√©flexion critique, compression glyphique et pilotage d‚Äôagents.

## üîç Objectif
Construire une intelligence artificielle modulaire et m√©morielle capable de :
- m√©moriser automatiquement chaque interaction utile
- r√©sumer en 3 niveaux (humain / hybride / glyphique)
- appeler des agents sp√©cialis√©s (Forge, R√©seau, Analyse‚Ä¶)
- agir avec rigueur, coh√©rence, sourcing et √©conomie de tokens

## üìÇ Structure projet

sentra_core_mem/
‚îú‚îÄ‚îÄ memory/ # M√©moire compress√©e (.json)
‚îú‚îÄ‚îÄ prompts/ # Prompts syst√®mes (ex : sentra_core.prompt.txt)
‚îú‚îÄ‚îÄ scripts/ # Fonctions Python appel√©es par main
‚îú‚îÄ‚îÄ SENTRA_OATH.md # Serment comportemental IA
‚îú‚îÄ‚îÄ glyph_rules.txt # Normes de compression glyphique (N3)
‚îú‚îÄ‚îÄ main.py # Point d'entr√©e local
‚îú‚îÄ‚îÄ .env # Cl√© API OpenAI
‚îî‚îÄ‚îÄ requirements.txt # D√©pendances


## üß† Fonctionnement
1. Chargement du prompt + m√©moire (5 derni√®res entr√©es)
2. R√©ponse GPT-4 avec :
   - R√©sum√© utilisateur
   - R√©sum√© glyphique
   - Sauvegarde auto dans `sentra_memory.json`
3. Rappel m√©moire sur demande (‚Äúr√©sume tout ce qui concerne le projet m√©moire‚Äù)

## üõ†Ô∏è Modules en d√©veloppement
- [x] M√©moire locale automatique
- [ ] M√©moire Notion (niveau 2)
- [ ] Appels vocaux via Discord
- [ ] Routage d'agents par sp√©cialit√© (SENTRA.FORGE, SENTRA.POST...)

---

# üîß UTILISATION TECHNIQUE (DOCS)

Syst√®me modulaire pour cr√©ation, compression et interrogation de **m√©moires IA/IA**.  
Utilise OpenAI GPT pour encoder, recharger et interagir avec des blocs de m√©moire compress√©e `.zmem`.

## ‚öôÔ∏è Fonctionnalit√©s principales

- üß† Encodage m√©moire IA sous format `.zmem` avec dictionnaire symbolique
- üîÅ Rechargement et interrogation par GPT (mode syst√®me)
- üì§ Export Markdown des m√©moires
- üß© Compatible Discord et Notion via agents
- üîí S√©paration configuration/API dans `/configs/`

## üöÄ Utilisation rapide

```bash
python scripts/zmem_encoder.py -i docs/mon_texte.txt -n TEST/MEM
python scripts/compose_prompt.py TEST/MEM
```

## üìÅ Structure

```
scripts/    ‚Üí encodeurs, agents, utilitaires
configs/    ‚Üí config OpenAI, Discord, Notion
memories/   ‚Üí .zmem compress√©s + .src lisibles
docs/       ‚Üí MANUEL, README, rapports Markdown
```

## üîê Configuration

- La cl√© API `OPENAI_API_KEY` doit √™tre d√©finie en variable d‚Äôenvironnement.
- Le fichier `configs/config.json` d√©finit le mod√®le, temp√©rature, etc.

- ## S√©curit√© des cl√©s API

La cl√© OpenAI (et toute cl√© sensible) ne doit jamais √™tre committ√©e dans le code ni dans les fichiers de configuration.  
Elle doit √™tre fournie comme **variable d‚Äôenvironnement** :

- **Sur Windows** :
  - Ouvrir PowerShell ou Git Bash
  - Ex√©cuter :  
    `setx OPENAI_API_KEY "ta-cl√©-ici"`
  - (Red√©marrer le terminal pour prise en compte)

- **Sur Render.com / autre h√©bergeur** :
  - Ajouter la variable dans les param√®tres ‚ÄúEnvironment Variables‚Äù du projet (OPENAI_API_KEY)

- **Sur GitHub Actions** :
  - D√©finir la cl√© comme ‚ÄúRepository Secret‚Äù (Settings > Secrets and variables > Actions > New repository secret)

> **Aucun fichier .env n‚Äôest fourni dans le repo.**  
> La cl√© reste priv√©e sur chaque environnement.

Les scripts Python lisent automatiquement la cl√© avec :
```python
import os
openai.api_key = os.getenv("OPENAI_API_KEY")




---

## Licence
Ce projet est distribu√©e sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus d'informations.

¬© 2025 ‚Äî Projet open-source modulable ‚ú®
