{
  "model": "gpt-4o",
  "temperature": 0.5,
  "max_tokens": 2048
}
